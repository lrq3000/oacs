<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3.1"/>
<title>OACS: C:/oacs/oacs/oacs/classifier/cansgaussian.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">OACS
   </div>
   <div id="projectbrief">Server-side anti-cheat system for online games</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Packages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('cansgaussian_8py_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Properties</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">cansgaussian.py</div>  </div>
</div><!--header-->
<div class="contents">
<a href="cansgaussian_8py.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno"><a class="code" href="namespaceoacs_1_1classifier_1_1cansgaussian.html">    1</a></span>&#160;<span class="comment">#!/usr/bin/env python</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"># encoding: utf-8</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">## @package cansgaussian</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">#</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"># CANS (Cluster Augmented Negative Selection Algorithm or Cluster Augmented Naive Bayes)</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="keyword">from</span> <a class="code" href="namespaceoacs_1_1classifier_1_1univariategaussian.html">oacs.classifier.univariategaussian</a> <span class="keyword">import</span> UnivariateGaussian</div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="keyword">from</span> <a class="code" href="namespaceoacs_1_1classifier_1_1multivariategaussian.html">oacs.classifier.multivariategaussian</a> <span class="keyword">import</span> MultivariateGaussian</div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="keyword">import</span> math</div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="keyword">import</span> numbers</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="keyword">from</span> numpy <span class="keyword">import</span> pi, exp, log</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> scoreatpercentile</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">## CANSGaussian</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment">#</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment"># CANS (Cluster Augmented Negative Selection Algorithm or Cluster Augmented Naive Bayes) is an AIS (Artificial Immune System) classifier class, which is a mix between UnivariateGaussian and MultivariateGaussian: highly correlated features (using Mutual Information) will be clustered and MultivariateGaussian will be used on them, and then a UnivariateGaussian will be performed on all the clusters (which may include only one feature or several correlated features)</span></div>
<div class="line"><a name="l00021"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html">   21</a></span>&#160;<span class="keyword">class </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html" title="CANSGaussian.">CANSGaussian</a>(<a class="code" href="classoacs_1_1classifier_1_1multivariategaussian_1_1_multivariate_gaussian.html" title="MultivariateGaussian.">MultivariateGaussian</a>, <a class="code" href="classoacs_1_1classifier_1_1univariategaussian_1_1_univariate_gaussian.html" title="UnivariateGaussian.">UnivariateGaussian</a>):</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;    <span class="comment">## @var config</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;    <span class="comment"># An instance of the ConfigParser object, already loaded</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;    <span class="comment">## Constructor</span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;    <span class="comment"># @param config An instance of the ConfigParser class</span></div>
<div class="line"><a name="l00028"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#aada166b3b754376430616f0d15f1fc73">   28</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#aada166b3b754376430616f0d15f1fc73" title="Constructor.">__init__</a>(self, config=None, *args, **kwargs):</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        <span class="keywordflow">return</span> MultivariateGaussian.__init__(self, config, *args, **kwargs)</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;    <span class="comment">## Learn the parameters from a given set X of examples, and labels Y</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    <span class="comment"># @param X Samples set</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <span class="comment"># @param Y Labels set (corresponding to X)</span></div>
<div class="line"><a name="l00034"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a18c0231979c4125eca41c994f895d6bb">   34</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a18c0231979c4125eca41c994f895d6bb" title="Learn the parameters from a given set X of examples, and labels Y.">learn</a>(self, X=None, Y=None, *args, **kwargs):</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;        weights = <span class="stringliteral">&#39;framerepeat&#39;</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;        <span class="comment"># == Preparing the samples set</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;        Yt = Y[Y==0].dropna() <span class="comment"># get the list of non-anomalous examples</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;        Xt = X.iloc[Yt.index] <span class="comment"># filter out anomalous examples and keep only non-anomalous ones</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;        <span class="comment"># == Computing the Mutual Information matrix (degree of correlation between each two features)</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;        <span class="comment"># Compute the required stats</span></div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;        Mu = self.<a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#afda8f025b8a28601976940591637b029" title="Compute the weighted mean of the dataset.">mean</a>(X, X[weights]) <span class="comment"># Mean</span></div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;        Var = self.<a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a1ae29cba16820e6b53ceed26531810f9" title="Compute the weighted unbiased variance of each feature for a given dataset.">variance</a>(X, Mu, X[weights]) <span class="comment"># Vector of variances</span></div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        <span class="comment">#Covar = self.covar(X, Mu, &#39;framerepeat&#39;) # Covariance matrix</span></div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;        H = CANSGaussian.entropy(X, Var) <span class="comment"># Entropy of each single variable (given its gaussian distribution)</span></div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;        <span class="comment">#H2 = CANSGaussian.entropypairwise_alt(X, Covar) # Joint entropy of each pair of two variables</span></div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;        H2 = CANSGaussian.entropypairwise(X, Mu, weights) <span class="comment"># Joint entropy of each pair of two variables</span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        <span class="comment"># Compute the Mutual Information matrix</span></div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        MI = CANSGaussian.mutualinformation(X, H, H2)</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;        <span class="comment"># Compute the clusters</span></div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        clusters = CANSGaussian.micluster(X, MI, cmax=self.config.config.get(<span class="stringliteral">&quot;cansgaussian_maxitemspercluster&quot;</span>, 1), mergeclusters=self.config.config.get(<span class="stringliteral">&quot;cansgaussian_mergeclusters&quot;</span>, <span class="keyword">False</span>), MImax=self.config.config.get(<span class="stringliteral">&quot;cansgaussian_scorethreshold&quot;</span>, <span class="keywordtype">None</span>))</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;        <span class="comment"># Computing the covariance matrixes for each subset of clusters</span></div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        Covar = []</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;        <span class="keywordflow">for</span> cind, cluster <span class="keywordflow">in</span> enumerate(clusters):</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;            <span class="comment"># Compute only if there is more than one feature in the cluster (else we will just use a UnivariateGaussian on this feature, thus we don&#39;t need the covariance matrix)</span></div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;            <span class="keywordflow">if</span> (len(cluster) &gt; 1):</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;                Covar.insert(cind, MultivariateGaussian.covar(X.ix[:, cluster], Mu[cluster], weights))</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;        <span class="keywordflow">return</span> {<span class="stringliteral">&#39;Mu&#39;</span>: Mu, <span class="stringliteral">&#39;Var&#39;</span>: Var, <span class="stringliteral">&#39;Covar&#39;</span>: Covar, <span class="stringliteral">&#39;H&#39;</span>: H, <span class="stringliteral">&#39;H2&#39;</span>: H2, <span class="stringliteral">&#39;MI&#39;</span>: MI, <span class="stringliteral">&#39;Clusters&#39;</span>: clusters} <span class="comment"># always return a dict of variables if you want your variables saved durably and accessible later</span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <span class="comment">## Multivariate gaussian prediction of the probability/class of an example given a set of parameters (weighted mean and covariance matrix)</span></div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    <span class="comment"># @param X One unknown example to label</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <span class="comment"># @param Mu Weighted mean of X</span></div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="comment"># @param Sigma2 Covariance matrix of X</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="comment"># TODO: compatibility with more than one sample (detect type==pdSseries)?</span></div>
<div class="line"><a name="l00072"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a841329982c83b08ade8261cc2c680acc">   72</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a841329982c83b08ade8261cc2c680acc" title="Multivariate gaussian prediction of the probability/class of an example given a set of parameters (we...">predict</a>(self, X=None, Clusters=None, Mu=None, Var=None, Covar=None, *args, **kwargs):</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;        <span class="keywordflow">if</span> <span class="stringliteral">&#39;framerepeat&#39;</span> <span class="keywordflow">in</span> X:</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;            X = X.drop([<span class="stringliteral">&#39;framerepeat&#39;</span>])</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        <span class="keywordflow">if</span> <span class="stringliteral">&#39;framerepeat&#39;</span> <span class="keywordflow">in</span> Mu:</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;            Mu = Mu.drop([<span class="stringliteral">&#39;framerepeat&#39;</span>])</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        <span class="keywordflow">if</span> <span class="stringliteral">&#39;framerepeat&#39;</span> <span class="keywordflow">in</span> Var:</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;            Var = Var.drop([<span class="stringliteral">&#39;framerepeat&#39;</span>])</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;        <span class="comment"># there cannot be the framerepeat column in the Covar list since it&#39;s taken care of at the learning process</span></div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;        Pred = pd.Series() <span class="comment"># Creating an empty vector</span></div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;        <span class="keywordflow">for</span> i, cluster <span class="keywordflow">in</span> enumerate(Clusters):</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;            <span class="comment"># Cluster contains several features, we compute the multivariate gaussian</span></div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;            <span class="keywordflow">if</span> len(cluster) &gt; 1:</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;                dictofvars = MultivariateGaussian._predict(X[cluster], Mu[cluster], Covar[i])</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;                Pred = Pred.set_value(<span class="stringliteral">&quot;C%i&quot;</span> % i, dictofvars[<span class="stringliteral">&#39;Prediction&#39;</span>] )</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;            <span class="comment"># Else there is only a single feature in this cluster, we just compute the univariate gaussian</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;            <span class="keywordflow">elif</span> len(cluster) == 1:</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;                feature = cluster[0]</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                dictofvars = UnivariateGaussian._predict(X[feature], Mu[feature], Var[feature])</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                Pred = Pred.set_value(<span class="stringliteral">&quot;C%i&quot;</span> % i, dictofvars[<span class="stringliteral">&#39;Prediction&#39;</span>] )</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;        <span class="comment"># Compute the product of all probabilities (p1 = proba of feature 1 being normal; p1*p2*p3*...*pn)</span></div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;        <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(Pred, numbers.Number):</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;            Pred = Pred.prod()</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;        <span class="keywordflow">return</span> {<span class="stringliteral">&#39;Prediction&#39;</span>: Pred} <span class="comment"># return the class of the sample(s)</span></div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    <span class="comment">## Compute the weighted mean of the dataset</span></div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    <span class="comment"># @param X Samples dataset</span></div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    <span class="comment"># @param weights Vector/Series of weights (ie: number of times one sample has to be repeated) - default: X[&#39;framerepeat&#39;]</span></div>
<div class="line"><a name="l00102"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#afda8f025b8a28601976940591637b029">  102</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#afda8f025b8a28601976940591637b029" title="Compute the weighted mean of the dataset.">mean</a>(self, X, weights=None):</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        <span class="keywordflow">return</span> UnivariateGaussian.mean(X, weights)</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;    <span class="comment">## Compute the weighted unbiased variance of each feature for a given dataset</span></div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    <span class="comment"># @param X Samples dataset</span></div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    <span class="comment"># @param mean Weighted mean</span></div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    <span class="comment"># @param weights Vector/Series of weights (ie: number of times one sample has to be repeated) - default: X[&#39;framerepeat&#39;]</span></div>
<div class="line"><a name="l00109"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a1ae29cba16820e6b53ceed26531810f9">  109</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a1ae29cba16820e6b53ceed26531810f9" title="Compute the weighted unbiased variance of each feature for a given dataset.">variance</a>(self, X, mean, weights=None):</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;        <span class="keywordflow">return</span> UnivariateGaussian.variance(X, mean, weights)</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    <span class="comment">## Compute the weighted covariance matrix of the dataset</span></div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;    <span class="comment"># Alternative to pandas.DataFrame.cov(), because pandas&#39;s and numpy&#39;s cov() can&#39;t account for weights (if you set mean = X.mean() and weights = None, then you&#39;ll get the exact same result as X.cov())</span></div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;    <span class="comment"># @param X One example or a dataset of examples (must have the same columns/keys as mean)</span></div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;    <span class="comment"># @param mean Weighted mean (must have the same columns/keys as X, else you will get a weird result, because pandas will still try to adapt and things will get really messed up!)</span></div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="comment"># @param weights Name of the weights column to remove from the final result (else it may flaw the computation of the prediction)</span></div>
<div class="line"><a name="l00117"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a07fdc47a85433f1a63059828fb5826a8">  117</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a07fdc47a85433f1a63059828fb5826a8" title="Compute the weighted covariance matrix of the dataset Alternative to pandas.DataFrame.cov(), because pandas&#39;s and numpy&#39;s cov() can&#39;t account for weights (if you set mean = X.mean() and weights = None, then you&#39;ll get the exact same result as X.cov())">covar</a>(self, X, mean, weights=None):</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;        <span class="keywordflow">return</span> MultivariateGaussian.covar(X, mean, weights)</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;    <span class="comment">## Compute the differential entropy vector for all features in X (entropy of one single variable, and differential = for continuous distributions)</span></div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;    <span class="comment"># Note: if you used WeightedNormalization before computing the entropy, the entropy will always be the same number for all features. This is normal (I guess! at least it&#39;s logical since the variance is normalized).</span></div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    <span class="comment"># @param X One example or a dataset of examples, only used to get the keys/indexes names (you can pass Var if Var contains the same keys as X)</span></div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;    <span class="comment"># @param Var Vector of variances of each feature in X</span></div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;    @staticmethod</div>
<div class="line"><a name="l00125"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a4fb6a2e84cbc441afca34453d4667a7a">  125</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a4fb6a2e84cbc441afca34453d4667a7a" title="Compute the differential entropy vector for all features in X (entropy of one single variable...">entropy</a>(X, Var):</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;        <span class="comment"># Create an empty vector (filled with NaN)</span></div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;        H = pd.Series(index=X.columns)</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;        <span class="comment"># For each feature (random variable)</span></div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;        <span class="keywordflow">for</span> index <span class="keywordflow">in</span> H.index:</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;            <span class="comment"># can use any base for the log here, the result will still be proportional thus we don&#39;t care the base</span></div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;            <span class="comment"># +1 is because log(e) = 1</span></div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;            H[index] = 0.5 * (<a class="code" href="namespaceoacs_1_1lib_1_1debug_1_1runsnakerun_1_1listviews.html#a87de87a6a539eae798c0c566b7a7c301">log</a>(2*pi*Var[index]) + 1)</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        <span class="keywordflow">return</span> H</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    <span class="comment">## Compute a two-by-two differential joint entropy matrix (a cell contains the value of the entropy between two variables)</span></div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    <span class="comment"># @param X One example or a dataset of examples (must have the same columns/keys as mean)</span></div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    <span class="comment"># @param mean Weighted mean (must have the same columns/keys as X, else you will get a weird result, because pandas will still try to adapt and things will get really messed up!)</span></div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    <span class="comment"># @param weights Name of the weights column to remove from the final result (else it may flaw the computation of the prediction)</span></div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    @staticmethod</div>
<div class="line"><a name="l00140"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a939f8ccda50f3f715ceceedb61f7b0b5">  140</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a939f8ccda50f3f715ceceedb61f7b0b5" title="Compute a two-by-two differential joint entropy matrix (a cell contains the value of the entropy betw...">entropypairwise</a>(X, mean, weights=None):</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;        <span class="comment"># Create an empty DataFrame (filled with NaN)</span></div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;        H2 = pd.DataFrame(index=X.columns, columns=X.columns)</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        k = 2 <span class="comment"># 2 dimensions here because we have 2 variables. If more, you can raise k</span></div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;        <span class="keywordflow">for</span> index <span class="keywordflow">in</span> H2.index:</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;            <span class="keywordflow">for</span> column <span class="keywordflow">in</span> H2.index:</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;                <span class="comment"># Diagonal is null: if it&#39;s the same index and column, no need to compute: a variable can&#39;t bring more information about itself</span></div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;                <span class="keywordflow">if</span> (index == column):</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;                    H2.ix[index, column] = 0 <span class="comment"># actually, computing the entropy would give the same result, but it&#39;s more computationally efficient to just set 0 here</span></div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;                <span class="comment"># By symetry, it&#39;s useless to recompute the lower part of the entropy matrix</span></div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                <span class="keywordflow">elif</span> (<span class="keywordflow">not</span> math.isnan(H2.ix[column, index]) <span class="keywordflow">and</span> H2.ix[column, index]):</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;                    H2.ix[index, column] = H2.ix[column, index]</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;                <span class="comment"># Compute the entropy by computing the log of the determinant of the covariance matrix</span></div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;                <span class="keywordflow">else</span>:</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;                    <span class="comment"># Compute the covariance of only the two variables (complexity O(2^2 * m) instead of O(m^2) if we computed the whole covariance matrix)</span></div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;                    <span class="comment"># Note: Computing the covariance of two variables is the same as computing the covariance of all variables and then slicing only the columns and indexes for those two variables</span></div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;                    <span class="comment"># Note2: this is equivalent only in terms of value, not in terms of computation efficiency (computing the covariance of two variables is of course a lot quicker)</span></div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;                    <span class="comment"># TODO: make the computation a bit quicker by precomputing: constant = log((2*pi*exp)^k) and then H2... = 0.5 * (constant + log(determinant))</span></div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;                    Covar = MultivariateGaussian.covar(X.ix[:,[index, column]], mean[[index, column]], weights)</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;                    <span class="comment"># Compute the joint entropy</span></div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;                    H2.ix[index, column] = 0.5 * <a class="code" href="namespaceoacs_1_1lib_1_1debug_1_1runsnakerun_1_1listviews.html#a87de87a6a539eae798c0c566b7a7c301">log</a>((2*pi*exp(1))**k * np.linalg.det(Covar.ix[[index, column],[index, column]]))</div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        <span class="keywordflow">return</span> H2</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    <span class="comment">## Compute a two-by-two differential joint entropy matrix (a cell contains the value of the entropy between two variables)</span></div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;    <span class="comment"># @param X One example or a dataset of examples, only used to get the keys/indexes names (you can pass Covar if Covar contains the same keys as X)</span></div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;    <span class="comment"># @param Covar Covariance matrix</span></div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;    @staticmethod</div>
<div class="line"><a name="l00168"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a86b4ddbc30421ab663dda731f96afc7e">  168</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a86b4ddbc30421ab663dda731f96afc7e" title="Compute a two-by-two differential joint entropy matrix (a cell contains the value of the entropy betw...">entropypairwise_alt</a>(X, Covar):</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        <span class="comment"># Create an empty DataFrame (filled with NaN)</span></div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        H2 = pd.DataFrame(index=X.columns, columns=X.columns)</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        k = 2 <span class="comment"># 2 dimensions here because we have 2 variables. If more, you can raise k</span></div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        <span class="keywordflow">for</span> index <span class="keywordflow">in</span> H2.index:</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;            <span class="keywordflow">for</span> column <span class="keywordflow">in</span> H2.index:</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;                <span class="comment"># Diagonal is null: if it&#39;s the same index and column, no need to compute: a variable can&#39;t bring more information about itself</span></div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;                <span class="keywordflow">if</span> (index == column):</div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;                    H2.ix[index, column] = 0 <span class="comment"># actually, computing the entropy would give the same result, but it&#39;s more computationally efficient to just set 0 here</span></div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;                <span class="comment"># By symetry, it&#39;s useless to recompute the lower part of the entropy matrix</span></div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;                <span class="keywordflow">elif</span> (<span class="keywordflow">not</span> math.isnan(H2.ix[column, index]) <span class="keywordflow">and</span> H2.ix[column, index]):</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;                    H2.ix[index, column] = H2.ix[column, index]</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;                <span class="comment"># Compute the entropy by computing the log of the determinant of the covariance matrix</span></div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                <span class="keywordflow">else</span>:</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;                    <span class="comment"># Note: Computing the covariance of two variables is the same as computing the covariance of all variables and then slicing only the columns and indexes for those two variables</span></div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;                    <span class="comment"># Note2: this is equivalent only in terms of value, not in terms of computation efficiency (computing the covariance of two variables is of course a lot quicker)</span></div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                    <span class="comment"># TODO: make the computation a bit quicker by precomputing: constant = log((2*pi*exp)^k) and then H2... = 0.5 * (constant + log(determinant))</span></div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;                    H2.ix[index, column] = 0.5 * <a class="code" href="namespaceoacs_1_1lib_1_1debug_1_1runsnakerun_1_1listviews.html#a87de87a6a539eae798c0c566b7a7c301">log</a>((2*pi*exp(1))**k * np.linalg.det(Covar.ix[[index, column],[index, column]]))</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;        <span class="keywordflow">return</span> H2</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    <span class="comment">## Compute the pairwise mutual information matrix for all features</span></div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;    <span class="comment"># Note: Kullback-Leibler divergence is a generalization of Mutual Information, thus this can also be seen as a KL divergence measurement.</span></div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    <span class="comment"># @param X One example or a dataset of examples, only used to get the keys/indexes names (you can pass H if H contains the same keys as X)</span></div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;    <span class="comment"># @param H Entropy vector for each single variable</span></div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    <span class="comment"># @param H2 Pairwise entropy matrix, containing the entropy between each couple of variables</span></div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;    @staticmethod</div>
<div class="line"><a name="l00195"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a590f0f4f5c508e01380908c015378507">  195</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a590f0f4f5c508e01380908c015378507" title="Compute the pairwise mutual information matrix for all features Note: Kullback-Leibler divergence is ...">mutualinformation</a>(X, H, H2):</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;        <span class="comment"># Create an empty DataFrame (filled with NaN)</span></div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;        MI = pd.DataFrame(index=X.columns, columns=X.columns)</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        <span class="comment"># For each two features (two random variables)</span></div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        <span class="keywordflow">for</span> index <span class="keywordflow">in</span> MI.index:</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;            <span class="keywordflow">for</span> column <span class="keywordflow">in</span> MI.columns:</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;                <span class="comment"># Diagonal is null: if it&#39;s the same index and column, no need to compute: a variable can&#39;t bring more information about itself</span></div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;                <span class="keywordflow">if</span> (index == column):</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;                    MI.ix[index, column] = H[index] <span class="comment"># MI[X|X] = entropy of X</span></div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;                <span class="comment"># By symetry, it&#39;s useless to recompute the lower part of the mutual information matrix</span></div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;                <span class="keywordflow">elif</span> (<span class="keywordflow">not</span> math.isnan(MI.ix[column, index]) <span class="keywordflow">and</span> MI.ix[column, index]):</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;                    MI.ix[index, column] = MI.ix[column, index]</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;                <span class="comment"># Else we compute the MI</span></div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;                <span class="keywordflow">else</span>:</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;                    <span class="comment"># I(X;X) &gt;= I(X;Y) (which means that any variable Y can only provide as much info about another var X as X can provide about itself), and I(X;X) = H(X), thus by doing H(X) + H(Y) - H(X;Y) the intuition is that we compute the maximum information one can have about X and Y (we know perfectly well X and Y) and we remove the mutual/joint entropy between X and Y (the entropy of both variables at once if they were happening simultaneously). And we know that H(X;Y) &lt;= H(X) + H(Y)</span></div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;                    MI.ix[index, column] = H[index] + H[column] - H2.ix[index, column]</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        <span class="keywordflow">return</span> MI</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;</div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;    <span class="comment">## Compute the clustering of features given a Mutual Information matrix</span></div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;    <span class="comment"># @param X One example or a dataset of examples, only used to get the keys/indexes names (you can pass MI if MI contains the same keys as X)</span></div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    <span class="comment"># @param MI Mutual Information matrix</span></div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;    <span class="comment"># @param cmax Maximum number of features per cluster (cmax=1 means that there&#39;s no limit)</span></div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;    <span class="comment"># @param mergeclusters Merge back the clusters together if features correlates whenever possible?</span></div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;    <span class="comment"># @param MImax Keep only MI scores above this threshold (MImax=&quot;mean&quot; will use the mean; MImax=[0..1] a float number between 0 and 1 will compute the percentile and drop below this percentile, Mimax=0.5 being the median; MImax=None means no threshold and no MI score dropped)</span></div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;    @staticmethod</div>
<div class="line"><a name="l00222"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a5e351cb6bb55cd22a8e372a1066ed09f">  222</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#a5e351cb6bb55cd22a8e372a1066ed09f" title="Compute the clustering of features given a Mutual Information matrix.">micluster</a>(X, MI, cmax=1, mergeclusters=False, MImax=None):</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;        <span class="comment">#== Preparing the Mutual Information data</span></div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        <span class="comment"># We preprocess the Mutual Information matrix into a sorted vector in descending order of MI score (from the best to the lowest). Each entry will have two keys associated: feature1 and feature2 being the respective names of the features (previously rows and columns).</span></div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;        <span class="comment"># Make sure data is float (number) and not object or string, and drop framerepeat column and row</span></div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;        MI = MI.astype(<span class="stringliteral">&#39;float64&#39;</span>).drop([<span class="stringliteral">&#39;framerepeat&#39;</span>], 1).drop([<span class="stringliteral">&#39;framerepeat&#39;</span>], 0)</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;        <span class="comment"># Unstack the Mutual Information matrix into a vector/Serie</span></div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        MI = MI.unstack().copy() <span class="comment"># Each entry will have two keys associated: feature1 and feature2 being the respective names of the features (previously rows and columns).</span></div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;        <span class="comment"># Sort by MI score</span></div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;        MI.sort(kind=<span class="stringliteral">&#39;mergesort&#39;</span>)</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;        <span class="comment"># Drop undefined scores</span></div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;        MI = MI.dropna()</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;        <span class="comment"># Reorder in descending order (because pandas&#39;s sort cannot yet sort in descending order, it always sort in ascending order)</span></div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;        MI = MI.ix[::-1]</div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;</div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;        <span class="comment"># MImax CUT: if MImax is defined, we drop all scores below this threshold</span></div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;        <span class="comment"># Cut by mean: all values below the mean of scores are dropped</span></div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;        <span class="keywordflow">if</span> (MImax <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> isinstance(MImax, basestring) <span class="keywordflow">and</span> MImax == <span class="stringliteral">&#39;mean&#39;</span>):</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;            <span class="comment"># Compute the mean and set all scores below as NaN</span></div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;            MI[MI &lt; MI.mean()] = float(<span class="stringliteral">&#39;NaN&#39;</span>)</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;            <span class="comment"># Drop these scores</span></div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;            MI = MI.dropna()</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;        <span class="comment"># Cut by percentile: compute the specified percentile and drop all scores below this threshold (percentile=0.5=median)</span></div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;        <span class="keywordflow">elif</span> (MImax <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> 0 &lt;= MImax*100 &lt;= 100):</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;            <span class="comment"># Compute the percentile and set all scores below as Nan</span></div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;            MI[MI &lt; scoreatpercentile(MI, MImax*100)] = float(<span class="stringliteral">&#39;NaN&#39;</span>)</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;            <span class="comment"># Drop these scores</span></div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;            MI = MI.dropna()</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;        <span class="comment">#== Clustering the features two-by-two</span></div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;        clusters = [] <span class="comment"># list of sublists, each sublists containing a set of features names that are bound together in the same cluster</span></div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;        assignments = pd.Series(index=X.columns) <span class="comment"># vector of assignments to keep track of which feature is assigned to which cluster</span></div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;        assignments = assignments.fillna(-1).drop(<span class="stringliteral">&#39;framerepeat&#39;</span>) <span class="comment"># initialize the vector with -1 and delete framerepeat (we don&#39;t want to bind it nor correlate it to other features)</span></div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;        curind = 0 <span class="comment"># Keep track of the current cluster index (because we want to keep track in the assignments vector)</span></div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;        <span class="comment">#-- First pass: Kruskal-like assignment algorithm</span></div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        <span class="comment"># We loop through all values of mutual informations and try to cluster together the variables which are the most correlated</span></div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        <span class="keywordflow">for</span> index <span class="keywordflow">in</span> MI.index:</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;            feature1 = index[0]</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;            feature2 = index[1]</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;            <span class="comment"># If the two labels are the same, we skip</span></div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;            <span class="keywordflow">if</span> (feature1 == feature2): <span class="keywordflow">continue</span></div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;            <span class="comment"># Both feature1 and feature2 are free (not bound to any cluster yet), and they have maximum correlation (at least better than the other choices or either previous choices were not possible because of CMAX CUT), then we bound them together in a new cluster</span></div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;            <span class="keywordflow">if</span> (assignments[feature1] == -1 <span class="keywordflow">and</span> assignments[feature2] == -1):</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;                <span class="comment"># Insert both features in a new cluster</span></div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;                clusters.insert(curind, [feature1, feature2])</div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;                <span class="comment"># Update the assignments table to keep track of where are assigned each feature</span></div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;                assignments[feature1] = curind</div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;                assignments[feature2] = curind</div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;                <span class="comment"># Increment the cluster index counter</span></div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;                curind += 1</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;            <span class="comment"># Feature1 is bound in a cluster but feature2 is free, we try to bind feature2 in the same cluster as feature1</span></div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;            <span class="keywordflow">elif</span> (assignments[feature1] != -1 <span class="keywordflow">and</span> assignments[feature2] == -1):</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;                <span class="comment"># Get the index of the cluster where the bound feature is assigned</span></div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;                ind = int(assignments[feature1]) <span class="comment"># convert from numpy types into standard python int type, necessary to be used as a list index</span></div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;                <span class="comment"># CMAX Cut: if we specified a number of items per cluster (cmax &gt; 1) and this cluster already contains the maximum number of items, we skip</span></div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;                <span class="keywordflow">if</span> (cmax &gt; 1 <span class="keywordflow">and</span> len(clusters[ind]) &gt;= cmax): <span class="keywordflow">continue</span></div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                <span class="comment"># Add feature2 into the same cluster as feature1</span></div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                clusters[ind].append(feature2)</div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;                <span class="comment"># Update the assignments table</span></div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;                assignments[feature2] = ind</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;            <span class="comment"># Same as the previous condition but the other way around (feature2 is bound and feature1 is free)</span></div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;            <span class="keywordflow">elif</span> (assignments[feature1] == -1 <span class="keywordflow">and</span> assignments[feature2] != -1):</div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;                <span class="comment"># Get the index of the cluster where the bound feature is assigned</span></div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;                ind = int(assignments[feature2]) <span class="comment"># convert from numpy types into standard python int type, necessary to be used as a list index</span></div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;                <span class="comment"># CMAX Cut: if we specified a number of items per cluster (cmax &gt; 1) and this cluster already contains the maximum number of items, we skip</span></div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;                <span class="keywordflow">if</span> (cmax &gt; 1 <span class="keywordflow">and</span> len(clusters[ind]) &gt;= cmax): <span class="keywordflow">continue</span></div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;                <span class="comment"># Add feature1 into the same cluster as feature2</span></div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;                clusters[ind].append(feature1)</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;                <span class="comment"># Update the assignments table</span></div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;                assignments[feature1] = ind</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;            <span class="comment"># Else, both features are already bound in a cluster, then we can&#39;t do anything OR we may recluster back together</span></div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;            <span class="keywordflow">elif</span> (assignments[feature1] != -1 <span class="keywordflow">and</span> assignments[feature2] != -1):</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;                <span class="comment"># Merge clusters back if possible and if the option is enabled</span></div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;                <span class="keywordflow">if</span> (mergeclusters):</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;                    ind1 = int(assignments[feature1])</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;                    ind2 = int(assignments[feature2])</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;                    <span class="comment"># Merge clusters if possible (if both features belong to different clusters)</span></div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;                    <span class="keywordflow">if</span> (ind1 != ind2):</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;                        <span class="comment"># if CMAX CUT doesn&#39;t prevent us from merging the clusters because that would merge too many items together</span></div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;                        <span class="keywordflow">if</span> (cmax &gt; 1 <span class="keywordflow">and</span> (len(clusters[ind1]) + len(clusters[ind2]) &gt; cmax)): <span class="keywordflow">continue</span></div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;                        <span class="comment"># Else we merge the clusters together</span></div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;                        clusters[ind1].extend(clusters[ind2]) <span class="comment"># merge both clusters together in the first one</span></div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;                        <span class="comment"># Re-assigning the variables from cluster2 to cluster1</span></div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;                        <span class="keywordflow">for</span> item <span class="keywordflow">in</span> clusters[ind2]:</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                            assignments[item] = ind1</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;                        <span class="comment"># Delete the second cluster</span></div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;                        del clusters[ind2]</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;                <span class="comment"># Else we don&#39;t want to recluster thus we just skip here</span></div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;                <span class="keywordflow">else</span>:</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;                    <span class="keywordflow">pass</span></div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;        <span class="comment">#-- Second pass: remaining unassigned variables/features get assigned to their own cluster</span></div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;        <span class="comment"># For each remaining unassigned variable, we simply create a new cluster containing only this variable</span></div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;        <span class="keywordflow">for</span> index <span class="keywordflow">in</span> assignments.index:</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;            <span class="keywordflow">if</span> (assignments[index] == -1):</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                clusters.insert(curind, [index])</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                assignments[index] = curind</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                curind += 1</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;        <span class="keywordflow">return</span> clusters</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    <span class="comment">## A simple function to print in neat tables the features given a list of clusters</span></div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;    <span class="comment"># @param clusters A list of clusters for the features</span></div>
<div class="line"><a name="l00328"></a><span class="lineno"><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#ae0518fbcb62feec25fb908240beca6a2">  328</a></span>&#160;    <span class="keyword">def </span><a class="code" href="classoacs_1_1classifier_1_1cansgaussian_1_1_c_a_n_s_gaussian.html#ae0518fbcb62feec25fb908240beca6a2" title="A simple function to print in neat tables the features given a list of clusters.">printclusters</a>(self, clusters):</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;        inc = 0</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;        <span class="keywordflow">for</span> tab <span class="keywordflow">in</span> clusters:</div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;            inc += 1</div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;            print(<span class="stringliteral">&quot;Tableau %s&quot;</span> % inc)</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;            <span class="keywordflow">for</span> item <span class="keywordflow">in</span> tab:</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;                print(<span class="stringliteral">&#39; &#39;</span>*5+<span class="stringliteral">&quot;%s&quot;</span> % item)</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;            print(<span class="stringliteral">&quot;&quot;</span>)</div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_95dea3d10c9f98c1baa90e87e0175c9f.html">oacs</a></li><li class="navelem"><a class="el" href="dir_3841315bfd9ffd1d6ca7b95fc4faf1e8.html">oacs</a></li><li class="navelem"><a class="el" href="dir_21b84646a66e1b24a785a648bc86a4ce.html">oacs</a></li><li class="navelem"><a class="el" href="dir_51dd90328ff251eb583b8af2d9707fd8.html">classifier</a></li><li class="navelem"><a class="el" href="cansgaussian_8py.html">cansgaussian.py</a></li>
    <li class="footer">Generated on Thu May 9 2013 17:43:10 for OACS by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3.1 </li>
  </ul>
</div>
</body>
</html>
